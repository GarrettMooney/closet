name: Data Pipeline

on:
  schedule:
    - cron: "0 0 * * 0" # Runs every Sunday at midnight UTC
  workflow_dispatch: # Allow manual triggering
  push:
    branches:
      - main

jobs:
  data-pipeline:
    runs-on: ubuntu-latest
    permissions:
      contents: write
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}

      - name: Install uv
        uses: astral-sh/setup-uv@v1

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.13"

      - name: Install system dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y ffmpeg

      - name: Install dependencies
        run: uv sync --locked

      - name: Setup YouTube cookies (if available)
        if: ${{ secrets.YOUTUBE_COOKIES }}
        run: |
          echo "${{ secrets.YOUTUBE_COOKIES }}" > data/cookies.txt
          echo "YOUTUBE_COOKIES_FILE=data/cookies.txt" >> $GITHUB_ENV

      - name: Run data pipeline
        run: uv run update-playlist
        env:
          GOOGLE_API_KEY: ${{ secrets.GOOGLE_API_KEY }}
          YOUTUBE_COOKIES_FILE: ${{ env.YOUTUBE_COOKIES_FILE }}

      - name: Clean up crumbs
        run: |
          if [ -f data/cookies.txt ]; then
            rm data/cookies.txt
          fi

      - name: Generate report
        run: uv run report

      - name: Conditional commit and push
        run: uv run scripts/conditional_commit.py

      - name: Upload log artifact
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: pipeline-log
          path: data/log.html
